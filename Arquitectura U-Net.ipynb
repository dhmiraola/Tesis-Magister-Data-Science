{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd756aa",
   "metadata": {},
   "source": [
    "# Eliminar cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283ac31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479865a8",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be5c9fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/600], Loss: 0.8907, Prec: 0.2098, Acc: 0.9589, Val_Loss: 0.8542, Val_Prec: 0.7703, Val_Acc: 0.9939, Time: 17.58 sec\n",
      "Val_dec (inf --> 0.854). Guardando...\n",
      "Epoch [2/600], Loss: 0.8504, Prec: 0.4732, Acc: 0.9921, Val_Loss: 0.8409, Val_Prec: 0.8333, Val_Acc: 0.9948, Time: 17.14 sec\n",
      "Val_dec (0.854 --> 0.841). Guardando...\n",
      "Epoch [3/600], Loss: 0.8360, Prec: 0.5119, Acc: 0.9929, Val_Loss: 0.8289, Val_Prec: 0.7242, Val_Acc: 0.9942, Time: 17.14 sec\n",
      "Val_dec (0.841 --> 0.829). Guardando...\n",
      "Epoch [4/600], Loss: 0.8234, Prec: 0.5318, Acc: 0.9930, Val_Loss: 0.8178, Val_Prec: 0.7893, Val_Acc: 0.9946, Time: 17.18 sec\n",
      "Val_dec (0.829 --> 0.818). Guardando...\n",
      "Epoch [5/600], Loss: 0.8118, Prec: 0.5528, Acc: 0.9933, Val_Loss: 0.8076, Val_Prec: 0.5997, Val_Acc: 0.9920, Time: 17.19 sec\n",
      "Val_dec (0.818 --> 0.808). Guardando...\n",
      "Epoch [6/600], Loss: 0.8016, Prec: 0.5152, Acc: 0.9930, Val_Loss: 0.7959, Val_Prec: 0.8411, Val_Acc: 0.9950, Time: 17.19 sec\n",
      "Val_dec (0.808 --> 0.796). Guardando...\n",
      "Epoch [7/600], Loss: 0.7917, Prec: 0.5577, Acc: 0.9936, Val_Loss: 0.7886, Val_Prec: 0.8508, Val_Acc: 0.9949, Time: 17.19 sec\n",
      "Val_dec (0.796 --> 0.789). Guardando...\n",
      "Epoch [8/600], Loss: 0.7832, Prec: 0.5451, Acc: 0.9934, Val_Loss: 0.7803, Val_Prec: 0.7971, Val_Acc: 0.9935, Time: 17.18 sec\n",
      "Val_dec (0.789 --> 0.780). Guardando...\n",
      "Epoch [9/600], Loss: 0.7752, Prec: 0.5729, Acc: 0.9937, Val_Loss: 0.7724, Val_Prec: 0.7838, Val_Acc: 0.9952, Time: 17.19 sec\n",
      "Val_dec (0.780 --> 0.772). Guardando...\n",
      "Epoch [10/600], Loss: 0.7681, Prec: 0.5744, Acc: 0.9939, Val_Loss: 0.7660, Val_Prec: 0.8130, Val_Acc: 0.9946, Time: 17.24 sec\n",
      "Val_dec (0.772 --> 0.766). Guardando...\n",
      "Epoch [11/600], Loss: 0.7618, Prec: 0.5723, Acc: 0.9939, Val_Loss: 0.7591, Val_Prec: 0.7285, Val_Acc: 0.9937, Time: 17.23 sec\n",
      "Val_dec (0.766 --> 0.759). Guardando...\n",
      "Epoch [12/600], Loss: 0.7561, Prec: 0.5729, Acc: 0.9939, Val_Loss: 0.7535, Val_Prec: 0.8146, Val_Acc: 0.9944, Time: 17.23 sec\n",
      "Val_dec (0.759 --> 0.753). Guardando...\n",
      "Epoch [13/600], Loss: 0.7511, Prec: 0.5682, Acc: 0.9938, Val_Loss: 0.7492, Val_Prec: 0.8062, Val_Acc: 0.9953, Time: 17.23 sec\n",
      "Val_dec (0.753 --> 0.749). Guardando...\n",
      "Epoch [14/600], Loss: 0.7463, Prec: 0.5922, Acc: 0.9940, Val_Loss: 0.7453, Val_Prec: 0.8061, Val_Acc: 0.9940, Time: 17.25 sec\n",
      "Val_dec (0.749 --> 0.745). Guardando...\n",
      "Epoch [15/600], Loss: 0.7423, Prec: 0.6105, Acc: 0.9942, Val_Loss: 0.7407, Val_Prec: 0.7897, Val_Acc: 0.9949, Time: 17.23 sec\n",
      "Val_dec (0.745 --> 0.741). Guardando...\n",
      "Epoch [16/600], Loss: 0.7388, Prec: 0.5969, Acc: 0.9941, Val_Loss: 0.7366, Val_Prec: 0.8248, Val_Acc: 0.9947, Time: 17.24 sec\n",
      "Val_dec (0.741 --> 0.737). Guardando...\n",
      "Epoch [17/600], Loss: 0.7353, Prec: 0.6213, Acc: 0.9945, Val_Loss: 0.7340, Val_Prec: 0.8265, Val_Acc: 0.9956, Time: 17.24 sec\n",
      "Val_dec (0.737 --> 0.734). Guardando...\n",
      "Epoch [18/600], Loss: 0.7325, Prec: 0.5990, Acc: 0.9943, Val_Loss: 0.7313, Val_Prec: 0.8320, Val_Acc: 0.9949, Time: 17.24 sec\n",
      "Val_dec (0.734 --> 0.731). Guardando...\n",
      "Epoch [19/600], Loss: 0.7298, Prec: 0.6158, Acc: 0.9944, Val_Loss: 0.7297, Val_Prec: 0.8639, Val_Acc: 0.9952, Time: 17.25 sec\n",
      "Val_dec (0.731 --> 0.730). Guardando...\n",
      "Epoch [20/600], Loss: 0.7273, Prec: 0.6372, Acc: 0.9946, Val_Loss: 0.7253, Val_Prec: 0.7369, Val_Acc: 0.9947, Time: 17.25 sec\n",
      "Val_dec (0.730 --> 0.725). Guardando...\n",
      "Epoch [21/600], Loss: 0.7253, Prec: 0.6306, Acc: 0.9946, Val_Loss: 0.7237, Val_Prec: 0.8404, Val_Acc: 0.9948, Time: 17.25 sec\n",
      "Val_dec (0.725 --> 0.724). Guardando...\n",
      "Epoch [22/600], Loss: 0.7234, Prec: 0.6234, Acc: 0.9945, Val_Loss: 0.7233, Val_Prec: 0.7644, Val_Acc: 0.9939, Time: 17.25 sec\n",
      "Val_dec (0.724 --> 0.723). Guardando...\n",
      "Epoch [23/600], Loss: 0.7218, Prec: 0.6383, Acc: 0.9944, Val_Loss: 0.7208, Val_Prec: 0.8115, Val_Acc: 0.9941, Time: 17.24 sec\n",
      "Val_dec (0.723 --> 0.721). Guardando...\n",
      "Epoch [24/600], Loss: 0.7200, Prec: 0.6521, Acc: 0.9948, Val_Loss: 0.7189, Val_Prec: 0.7949, Val_Acc: 0.9951, Time: 17.26 sec\n",
      "Val_dec (0.721 --> 0.719). Guardando...\n",
      "Epoch [25/600], Loss: 0.7188, Prec: 0.6246, Acc: 0.9944, Val_Loss: 0.7186, Val_Prec: 0.8164, Val_Acc: 0.9950, Time: 17.24 sec\n",
      "Val_dec (0.719 --> 0.719). Guardando...\n",
      "Epoch [26/600], Loss: 0.7177, Prec: 0.6185, Acc: 0.9944, Val_Loss: 0.7166, Val_Prec: 0.6822, Val_Acc: 0.9928, Time: 17.25 sec\n",
      "Val_dec (0.719 --> 0.717). Guardando...\n",
      "Epoch [27/600], Loss: 0.7166, Prec: 0.6045, Acc: 0.9943, Val_Loss: 0.7158, Val_Prec: 0.8523, Val_Acc: 0.9956, Time: 17.25 sec\n",
      "Val_dec (0.717 --> 0.716). Guardando...\n",
      "Epoch [28/600], Loss: 0.7153, Prec: 0.6261, Acc: 0.9946, Val_Loss: 0.7150, Val_Prec: 0.8263, Val_Acc: 0.9950, Time: 17.24 sec\n",
      "Val_dec (0.716 --> 0.715). Guardando...\n",
      "Epoch [29/600], Loss: 0.7143, Prec: 0.6207, Acc: 0.9947, Val_Loss: 0.7138, Val_Prec: 0.6920, Val_Acc: 0.9928, Time: 17.25 sec\n",
      "Val_dec (0.715 --> 0.714). Guardando...\n",
      "Epoch [30/600], Loss: 0.7134, Prec: 0.6423, Acc: 0.9946, Val_Loss: 0.7139, Val_Prec: 0.8613, Val_Acc: 0.9952, Time: 17.22 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [31/600], Loss: 0.7127, Prec: 0.6381, Acc: 0.9945, Val_Loss: 0.7116, Val_Prec: 0.7977, Val_Acc: 0.9953, Time: 17.24 sec\n",
      "Val_dec (0.714 --> 0.712). Guardando...\n",
      "Epoch [32/600], Loss: 0.7119, Prec: 0.6467, Acc: 0.9948, Val_Loss: 0.7125, Val_Prec: 0.8472, Val_Acc: 0.9952, Time: 17.23 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [33/600], Loss: 0.7112, Prec: 0.6597, Acc: 0.9947, Val_Loss: 0.7114, Val_Prec: 0.8133, Val_Acc: 0.9953, Time: 17.28 sec\n",
      "Val_dec (0.712 --> 0.711). Guardando...\n",
      "Epoch [34/600], Loss: 0.7105, Prec: 0.6681, Acc: 0.9949, Val_Loss: 0.7104, Val_Prec: 0.8498, Val_Acc: 0.9956, Time: 17.24 sec\n",
      "Val_dec (0.711 --> 0.710). Guardando...\n",
      "Epoch [35/600], Loss: 0.7099, Prec: 0.6308, Acc: 0.9947, Val_Loss: 0.7093, Val_Prec: 0.7392, Val_Acc: 0.9952, Time: 17.26 sec\n",
      "Val_dec (0.710 --> 0.709). Guardando...\n",
      "Epoch [36/600], Loss: 0.7094, Prec: 0.6548, Acc: 0.9948, Val_Loss: 0.7094, Val_Prec: 0.8670, Val_Acc: 0.9957, Time: 17.25 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [37/600], Loss: 0.7089, Prec: 0.6496, Acc: 0.9949, Val_Loss: 0.7098, Val_Prec: 0.9138, Val_Acc: 0.9954, Time: 17.28 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [38/600], Loss: 0.7083, Prec: 0.6732, Acc: 0.9950, Val_Loss: 0.7080, Val_Prec: 0.8359, Val_Acc: 0.9952, Time: 17.26 sec\n",
      "Val_dec (0.709 --> 0.708). Guardando...\n",
      "Epoch [39/600], Loss: 0.7079, Prec: 0.6830, Acc: 0.9950, Val_Loss: 0.7090, Val_Prec: 0.8679, Val_Acc: 0.9952, Time: 17.24 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [40/600], Loss: 0.7077, Prec: 0.6502, Acc: 0.9950, Val_Loss: 0.7071, Val_Prec: 0.8273, Val_Acc: 0.9950, Time: 17.25 sec\n",
      "Val_dec (0.708 --> 0.707). Guardando...\n",
      "Epoch [41/600], Loss: 0.7071, Prec: 0.6898, Acc: 0.9951, Val_Loss: 0.7067, Val_Prec: 0.7957, Val_Acc: 0.9946, Time: 17.27 sec\n",
      "Val_dec (0.707 --> 0.707). Guardando...\n",
      "Epoch [42/600], Loss: 0.7068, Prec: 0.6794, Acc: 0.9952, Val_Loss: 0.7065, Val_Prec: 0.8171, Val_Acc: 0.9948, Time: 17.23 sec\n",
      "Val_dec (0.707 --> 0.706). Guardando...\n",
      "Epoch [43/600], Loss: 0.7063, Prec: 0.7361, Acc: 0.9953, Val_Loss: 0.7063, Val_Prec: 0.8461, Val_Acc: 0.9955, Time: 17.26 sec\n",
      "Val_dec (0.706 --> 0.706). Guardando...\n",
      "Epoch [44/600], Loss: 0.7063, Prec: 0.7086, Acc: 0.9951, Val_Loss: 0.7059, Val_Prec: 0.8074, Val_Acc: 0.9951, Time: 17.27 sec\n",
      "Val_dec (0.706 --> 0.706). Guardando...\n",
      "Epoch [45/600], Loss: 0.7060, Prec: 0.7003, Acc: 0.9951, Val_Loss: 0.7068, Val_Prec: 0.8768, Val_Acc: 0.9955, Time: 17.24 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [46/600], Loss: 0.7056, Prec: 0.7164, Acc: 0.9953, Val_Loss: 0.7060, Val_Prec: 0.8609, Val_Acc: 0.9952, Time: 17.25 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [47/600], Loss: 0.7054, Prec: 0.7098, Acc: 0.9953, Val_Loss: 0.7051, Val_Prec: 0.8110, Val_Acc: 0.9953, Time: 17.27 sec\n",
      "Val_dec (0.706 --> 0.705). Guardando...\n",
      "Epoch [48/600], Loss: 0.7053, Prec: 0.6945, Acc: 0.9952, Val_Loss: 0.7061, Val_Prec: 0.8509, Val_Acc: 0.9951, Time: 17.25 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [49/600], Loss: 0.7050, Prec: 0.7006, Acc: 0.9954, Val_Loss: 0.7070, Val_Prec: 0.9046, Val_Acc: 0.9949, Time: 17.28 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [50/600], Loss: 0.7049, Prec: 0.7021, Acc: 0.9953, Val_Loss: 0.7054, Val_Prec: 0.8258, Val_Acc: 0.9949, Time: 17.29 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [51/600], Loss: 0.7046, Prec: 0.7081, Acc: 0.9953, Val_Loss: 0.7044, Val_Prec: 0.7674, Val_Acc: 0.9956, Time: 17.26 sec\n",
      "Val_dec (0.705 --> 0.704). Guardando...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/600], Loss: 0.7044, Prec: 0.7118, Acc: 0.9953, Val_Loss: 0.7050, Val_Prec: 0.8017, Val_Acc: 0.9954, Time: 17.28 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [53/600], Loss: 0.7044, Prec: 0.7201, Acc: 0.9954, Val_Loss: 0.7040, Val_Prec: 0.8090, Val_Acc: 0.9953, Time: 17.26 sec\n",
      "Val_dec (0.704 --> 0.704). Guardando...\n",
      "Epoch [54/600], Loss: 0.7045, Prec: 0.6845, Acc: 0.9950, Val_Loss: 0.7056, Val_Prec: 0.8909, Val_Acc: 0.9952, Time: 17.27 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [55/600], Loss: 0.7042, Prec: 0.7203, Acc: 0.9953, Val_Loss: 0.7038, Val_Prec: 0.8119, Val_Acc: 0.9953, Time: 17.29 sec\n",
      "Val_dec (0.704 --> 0.704). Guardando...\n",
      "Epoch [56/600], Loss: 0.7037, Prec: 0.7352, Acc: 0.9956, Val_Loss: 0.7043, Val_Prec: 0.8680, Val_Acc: 0.9955, Time: 17.28 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [57/600], Loss: 0.7036, Prec: 0.7429, Acc: 0.9956, Val_Loss: 0.7041, Val_Prec: 0.8272, Val_Acc: 0.9947, Time: 17.27 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [58/600], Loss: 0.7036, Prec: 0.7437, Acc: 0.9955, Val_Loss: 0.7041, Val_Prec: 0.8356, Val_Acc: 0.9956, Time: 17.28 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [59/600], Loss: 0.7034, Prec: 0.7410, Acc: 0.9956, Val_Loss: 0.7036, Val_Prec: 0.8203, Val_Acc: 0.9953, Time: 17.26 sec\n",
      "Val_dec (0.704 --> 0.704). Guardando...\n",
      "Epoch [60/600], Loss: 0.7033, Prec: 0.7555, Acc: 0.9956, Val_Loss: 0.7032, Val_Prec: 0.8354, Val_Acc: 0.9957, Time: 17.26 sec\n",
      "Val_dec (0.704 --> 0.703). Guardando...\n",
      "Epoch [61/600], Loss: 0.7033, Prec: 0.7155, Acc: 0.9955, Val_Loss: 0.7035, Val_Prec: 0.8684, Val_Acc: 0.9956, Time: 17.25 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [62/600], Loss: 0.7030, Prec: 0.7543, Acc: 0.9957, Val_Loss: 0.7031, Val_Prec: 0.8472, Val_Acc: 0.9956, Time: 17.25 sec\n",
      "Val_dec (0.703 --> 0.703). Guardando...\n",
      "Epoch [63/600], Loss: 0.7031, Prec: 0.7115, Acc: 0.9955, Val_Loss: 0.7031, Val_Prec: 0.8174, Val_Acc: 0.9954, Time: 17.28 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [64/600], Loss: 0.7030, Prec: 0.7571, Acc: 0.9956, Val_Loss: 0.7029, Val_Prec: 0.7952, Val_Acc: 0.9953, Time: 17.27 sec\n",
      "Val_dec (0.703 --> 0.703). Guardando...\n",
      "Epoch [65/600], Loss: 0.7028, Prec: 0.7514, Acc: 0.9958, Val_Loss: 0.7028, Val_Prec: 0.8269, Val_Acc: 0.9957, Time: 17.29 sec\n",
      "Val_dec (0.703 --> 0.703). Guardando...\n",
      "Epoch [66/600], Loss: 0.7028, Prec: 0.7503, Acc: 0.9956, Val_Loss: 0.7031, Val_Prec: 0.8622, Val_Acc: 0.9957, Time: 17.30 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [67/600], Loss: 0.7027, Prec: 0.7657, Acc: 0.9958, Val_Loss: 0.7047, Val_Prec: 0.9116, Val_Acc: 0.9951, Time: 17.30 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [68/600], Loss: 0.7030, Prec: 0.7240, Acc: 0.9954, Val_Loss: 0.7037, Val_Prec: 0.8742, Val_Acc: 0.9955, Time: 17.30 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [69/600], Loss: 0.7030, Prec: 0.7169, Acc: 0.9954, Val_Loss: 0.7037, Val_Prec: 0.6560, Val_Acc: 0.9923, Time: 17.28 sec\n",
      "Counter: 4 out of 15\n",
      "Epoch [70/600], Loss: 0.7026, Prec: 0.7614, Acc: 0.9957, Val_Loss: 0.7032, Val_Prec: 0.8515, Val_Acc: 0.9954, Time: 17.29 sec\n",
      "Counter: 5 out of 15\n",
      "Epoch [71/600], Loss: 0.7026, Prec: 0.7738, Acc: 0.9956, Val_Loss: 0.7028, Val_Prec: 0.8595, Val_Acc: 0.9955, Time: 17.30 sec\n",
      "Val_dec (0.703 --> 0.703). Guardando...\n",
      "Epoch [72/600], Loss: 0.7024, Prec: 0.7606, Acc: 0.9957, Val_Loss: 0.7033, Val_Prec: 0.9040, Val_Acc: 0.9958, Time: 17.33 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [73/600], Loss: 0.7023, Prec: 0.7703, Acc: 0.9959, Val_Loss: 0.7034, Val_Prec: 0.8823, Val_Acc: 0.9956, Time: 17.29 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [74/600], Loss: 0.7023, Prec: 0.7607, Acc: 0.9958, Val_Loss: 0.7036, Val_Prec: 0.8765, Val_Acc: 0.9956, Time: 17.32 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [75/600], Loss: 0.7023, Prec: 0.7768, Acc: 0.9958, Val_Loss: 0.7029, Val_Prec: 0.8635, Val_Acc: 0.9955, Time: 17.30 sec\n",
      "Counter: 4 out of 15\n",
      "Epoch [76/600], Loss: 0.7022, Prec: 0.7931, Acc: 0.9960, Val_Loss: 0.7025, Val_Prec: 0.8309, Val_Acc: 0.9952, Time: 17.30 sec\n",
      "Val_dec (0.703 --> 0.703). Guardando...\n",
      "Epoch [77/600], Loss: 0.7022, Prec: 0.7696, Acc: 0.9958, Val_Loss: 0.7025, Val_Prec: 0.8545, Val_Acc: 0.9957, Time: 17.29 sec\n",
      "Val_dec (0.703 --> 0.702). Guardando...\n",
      "Epoch [78/600], Loss: 0.7022, Prec: 0.8038, Acc: 0.9959, Val_Loss: 0.7026, Val_Prec: 0.8413, Val_Acc: 0.9958, Time: 17.31 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [79/600], Loss: 0.7023, Prec: 0.7554, Acc: 0.9956, Val_Loss: 0.7021, Val_Prec: 0.8256, Val_Acc: 0.9954, Time: 17.33 sec\n",
      "Val_dec (0.702 --> 0.702). Guardando...\n",
      "Epoch [80/600], Loss: 0.7021, Prec: 0.7668, Acc: 0.9959, Val_Loss: 0.7020, Val_Prec: 0.7902, Val_Acc: 0.9951, Time: 17.27 sec\n",
      "Val_dec (0.702 --> 0.702). Guardando...\n",
      "Epoch [81/600], Loss: 0.7022, Prec: 0.7384, Acc: 0.9957, Val_Loss: 0.7024, Val_Prec: 0.8578, Val_Acc: 0.9957, Time: 17.29 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [82/600], Loss: 0.7018, Prec: 0.7957, Acc: 0.9961, Val_Loss: 0.7021, Val_Prec: 0.8365, Val_Acc: 0.9955, Time: 17.26 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [83/600], Loss: 0.7018, Prec: 0.7982, Acc: 0.9961, Val_Loss: 0.7033, Val_Prec: 0.9011, Val_Acc: 0.9957, Time: 17.25 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [84/600], Loss: 0.7018, Prec: 0.7866, Acc: 0.9961, Val_Loss: 0.7035, Val_Prec: 0.8999, Val_Acc: 0.9953, Time: 17.27 sec\n",
      "Counter: 4 out of 15\n",
      "Epoch [85/600], Loss: 0.7019, Prec: 0.7796, Acc: 0.9960, Val_Loss: 0.7034, Val_Prec: 0.8893, Val_Acc: 0.9954, Time: 17.29 sec\n",
      "Counter: 5 out of 15\n",
      "Epoch [86/600], Loss: 0.7017, Prec: 0.7925, Acc: 0.9961, Val_Loss: 0.7022, Val_Prec: 0.8186, Val_Acc: 0.9950, Time: 17.28 sec\n",
      "Counter: 6 out of 15\n",
      "Epoch [87/600], Loss: 0.7018, Prec: 0.7931, Acc: 0.9960, Val_Loss: 0.7040, Val_Prec: 0.8989, Val_Acc: 0.9950, Time: 17.28 sec\n",
      "Counter: 7 out of 15\n",
      "Epoch [88/600], Loss: 0.7018, Prec: 0.8025, Acc: 0.9960, Val_Loss: 0.7052, Val_Prec: 0.8434, Val_Acc: 0.9947, Time: 17.27 sec\n",
      "Counter: 8 out of 15\n",
      "Epoch [89/600], Loss: 0.7016, Prec: 0.7918, Acc: 0.9961, Val_Loss: 0.7038, Val_Prec: 0.9207, Val_Acc: 0.9954, Time: 17.29 sec\n",
      "Counter: 9 out of 15\n",
      "Epoch [90/600], Loss: 0.7018, Prec: 0.7997, Acc: 0.9960, Val_Loss: 0.7028, Val_Prec: 0.8511, Val_Acc: 0.9953, Time: 17.26 sec\n",
      "Counter: 10 out of 15\n",
      "Epoch [91/600], Loss: 0.7016, Prec: 0.8084, Acc: 0.9961, Val_Loss: 0.7019, Val_Prec: 0.8205, Val_Acc: 0.9956, Time: 17.27 sec\n",
      "Val_dec (0.702 --> 0.702). Guardando...\n",
      "Epoch [92/600], Loss: 0.7015, Prec: 0.8259, Acc: 0.9963, Val_Loss: 0.7020, Val_Prec: 0.8191, Val_Acc: 0.9950, Time: 17.29 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [93/600], Loss: 0.7016, Prec: 0.8049, Acc: 0.9960, Val_Loss: 0.7034, Val_Prec: 0.9033, Val_Acc: 0.9955, Time: 17.30 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [94/600], Loss: 0.7014, Prec: 0.8195, Acc: 0.9963, Val_Loss: 0.7028, Val_Prec: 0.8871, Val_Acc: 0.9956, Time: 17.27 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [95/600], Loss: 0.7015, Prec: 0.8263, Acc: 0.9962, Val_Loss: 0.7032, Val_Prec: 0.8857, Val_Acc: 0.9956, Time: 17.28 sec\n",
      "Counter: 4 out of 15\n",
      "Epoch [96/600], Loss: 0.7016, Prec: 0.7882, Acc: 0.9961, Val_Loss: 0.7032, Val_Prec: 0.8660, Val_Acc: 0.9950, Time: 17.29 sec\n",
      "Counter: 5 out of 15\n",
      "Epoch [97/600], Loss: 0.7015, Prec: 0.8250, Acc: 0.9963, Val_Loss: 0.7019, Val_Prec: 0.8221, Val_Acc: 0.9957, Time: 17.28 sec\n",
      "Val_dec (0.702 --> 0.702). Guardando...\n",
      "Epoch [98/600], Loss: 0.7014, Prec: 0.8207, Acc: 0.9963, Val_Loss: 0.7020, Val_Prec: 0.8729, Val_Acc: 0.9959, Time: 17.28 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [99/600], Loss: 0.7014, Prec: 0.8167, Acc: 0.9963, Val_Loss: 0.7021, Val_Prec: 0.8485, Val_Acc: 0.9954, Time: 17.30 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [100/600], Loss: 0.7017, Prec: 0.7639, Acc: 0.9959, Val_Loss: 0.7034, Val_Prec: 0.8929, Val_Acc: 0.9950, Time: 17.29 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [101/600], Loss: 0.7015, Prec: 0.8354, Acc: 0.9962, Val_Loss: 0.7019, Val_Prec: 0.8665, Val_Acc: 0.9959, Time: 17.28 sec\n",
      "Counter: 4 out of 15\n",
      "Epoch [102/600], Loss: 0.7014, Prec: 0.8044, Acc: 0.9962, Val_Loss: 0.7032, Val_Prec: 0.9011, Val_Acc: 0.9954, Time: 17.26 sec\n",
      "Counter: 5 out of 15\n",
      "Epoch [103/600], Loss: 0.7013, Prec: 0.8260, Acc: 0.9963, Val_Loss: 0.7028, Val_Prec: 0.8739, Val_Acc: 0.9955, Time: 17.25 sec\n",
      "Counter: 6 out of 15\n",
      "Epoch [104/600], Loss: 0.7014, Prec: 0.8029, Acc: 0.9963, Val_Loss: 0.7025, Val_Prec: 0.8640, Val_Acc: 0.9950, Time: 17.28 sec\n",
      "Counter: 7 out of 15\n",
      "Epoch [105/600], Loss: 0.7013, Prec: 0.8418, Acc: 0.9964, Val_Loss: 0.7027, Val_Prec: 0.8704, Val_Acc: 0.9954, Time: 17.27 sec\n",
      "Counter: 8 out of 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/600], Loss: 0.7012, Prec: 0.8432, Acc: 0.9965, Val_Loss: 0.7034, Val_Prec: 0.9034, Val_Acc: 0.9954, Time: 17.28 sec\n",
      "Counter: 9 out of 15\n",
      "Epoch [107/600], Loss: 0.7014, Prec: 0.8162, Acc: 0.9962, Val_Loss: 0.7045, Val_Prec: 0.9091, Val_Acc: 0.9950, Time: 17.28 sec\n",
      "Counter: 10 out of 15\n",
      "Epoch [108/600], Loss: 0.7013, Prec: 0.8272, Acc: 0.9964, Val_Loss: 0.7020, Val_Prec: 0.8601, Val_Acc: 0.9956, Time: 17.26 sec\n",
      "Counter: 11 out of 15\n",
      "Epoch [109/600], Loss: 0.7012, Prec: 0.8603, Acc: 0.9965, Val_Loss: 0.7021, Val_Prec: 0.8941, Val_Acc: 0.9959, Time: 17.29 sec\n",
      "Counter: 12 out of 15\n",
      "Epoch [110/600], Loss: 0.7014, Prec: 0.7850, Acc: 0.9962, Val_Loss: 0.7013, Val_Prec: 0.8219, Val_Acc: 0.9959, Time: 17.28 sec\n",
      "Val_dec (0.702 --> 0.701). Guardando...\n",
      "Epoch [111/600], Loss: 0.7014, Prec: 0.8171, Acc: 0.9962, Val_Loss: 0.7031, Val_Prec: 0.8692, Val_Acc: 0.9951, Time: 17.32 sec\n",
      "Counter: 1 out of 15\n",
      "Epoch [112/600], Loss: 0.7015, Prec: 0.7921, Acc: 0.9961, Val_Loss: 0.7030, Val_Prec: 0.9005, Val_Acc: 0.9957, Time: 17.32 sec\n",
      "Counter: 2 out of 15\n",
      "Epoch [113/600], Loss: 0.7012, Prec: 0.8453, Acc: 0.9964, Val_Loss: 0.7025, Val_Prec: 0.8635, Val_Acc: 0.9956, Time: 17.31 sec\n",
      "Counter: 3 out of 15\n",
      "Epoch [114/600], Loss: 0.7012, Prec: 0.8353, Acc: 0.9965, Val_Loss: 0.7034, Val_Prec: 0.9053, Val_Acc: 0.9954, Time: 17.32 sec\n",
      "Counter: 4 out of 15\n",
      "Epoch [115/600], Loss: 0.7012, Prec: 0.8356, Acc: 0.9964, Val_Loss: 0.7025, Val_Prec: 0.8833, Val_Acc: 0.9954, Time: 17.31 sec\n",
      "Counter: 5 out of 15\n",
      "Epoch [116/600], Loss: 0.7011, Prec: 0.8396, Acc: 0.9965, Val_Loss: 0.7031, Val_Prec: 0.9061, Val_Acc: 0.9956, Time: 17.31 sec\n",
      "Counter: 6 out of 15\n",
      "Epoch [117/600], Loss: 0.7011, Prec: 0.8483, Acc: 0.9965, Val_Loss: 0.7033, Val_Prec: 0.9034, Val_Acc: 0.9955, Time: 17.29 sec\n",
      "Counter: 7 out of 15\n",
      "Epoch [118/600], Loss: 0.7010, Prec: 0.8675, Acc: 0.9966, Val_Loss: 0.7034, Val_Prec: 0.9064, Val_Acc: 0.9954, Time: 17.31 sec\n",
      "Counter: 8 out of 15\n",
      "Epoch [119/600], Loss: 0.7011, Prec: 0.8509, Acc: 0.9964, Val_Loss: 0.7021, Val_Prec: 0.8795, Val_Acc: 0.9957, Time: 17.31 sec\n",
      "Counter: 9 out of 15\n",
      "Epoch [120/600], Loss: 0.7010, Prec: 0.8614, Acc: 0.9965, Val_Loss: 0.7035, Val_Prec: 0.9043, Val_Acc: 0.9954, Time: 17.30 sec\n",
      "Counter: 10 out of 15\n",
      "Epoch [121/600], Loss: 0.7010, Prec: 0.8337, Acc: 0.9966, Val_Loss: 0.7031, Val_Prec: 0.9030, Val_Acc: 0.9956, Time: 17.33 sec\n",
      "Counter: 11 out of 15\n",
      "Epoch [122/600], Loss: 0.7010, Prec: 0.8742, Acc: 0.9966, Val_Loss: 0.7023, Val_Prec: 0.8812, Val_Acc: 0.9958, Time: 17.33 sec\n",
      "Counter: 12 out of 15\n",
      "Epoch [123/600], Loss: 0.7010, Prec: 0.8619, Acc: 0.9965, Val_Loss: 0.7017, Val_Prec: 0.8375, Val_Acc: 0.9955, Time: 17.30 sec\n",
      "Counter: 13 out of 15\n",
      "Epoch [124/600], Loss: 0.7010, Prec: 0.8433, Acc: 0.9965, Val_Loss: 0.7028, Val_Prec: 0.8988, Val_Acc: 0.9954, Time: 17.31 sec\n",
      "Counter: 14 out of 15\n",
      "Epoch [125/600], Loss: 0.7011, Prec: 0.8552, Acc: 0.9965, Val_Loss: 0.7015, Val_Prec: 0.7945, Val_Acc: 0.9957, Time: 17.34 sec\n",
      "Counter: 15 out of 15\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import time\n",
    "from torchvision.transforms import functional as TF\n",
    "import random\n",
    "\n",
    "# UNet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        # Codificador\n",
    "        self.encoder1 = self._block(in_channels, 32)\n",
    "        self.encoder2 = self._block(32, 64)\n",
    "        self.encoder3 = self._block(64, 128)\n",
    "        self.encoder4 = self._block(128, 256)\n",
    "        self.encoder5 = self._block(256, 512)\n",
    "        self.encoder6 = self._block(512, 1024)\n",
    "        self.encoder7 = self._block(1024, 2048)\n",
    "\n",
    "        # Decodificador\n",
    "        self.upconv7 = nn.ConvTranspose2d(2048, 1024, kernel_size=2, stride=2)\n",
    "        self.decoder7 = self._block(2048, 1024)\n",
    "        self.upconv6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.decoder6 = self._block(1024, 512)\n",
    "        self.upconv5 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder5 = self._block(512, 256)\n",
    "        self.upconv4 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self._block(256, 128)\n",
    "        self.upconv3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self._block(128, 64)\n",
    "        self.upconv2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self._block(64, 32)\n",
    "        self.decoder1 = self._block(32, 32, out_channels=out_channels, final_layer=True)  \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def _block(self, in_channels, features, out_channels=None, final_layer=False): \n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(features, features, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if final_layer:\n",
    "            layers.append(nn.Conv2d(features, out_channels, kernel_size=1))  \n",
    "            layers.append(nn.Sigmoid())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "        enc5 = self.encoder5(self.pool(enc4))\n",
    "        enc6 = self.encoder6(self.pool(enc5))\n",
    "        enc7 = self.encoder7(self.pool(enc6))\n",
    "\n",
    "        dec7 = self.upconv7(enc7)\n",
    "        dec7 = torch.cat((dec7, enc6), dim=1)\n",
    "        dec7 = self.decoder7(dec7)\n",
    "        dec6 = self.upconv6(dec7)\n",
    "        dec6 = torch.cat((dec6, enc5), dim=1)\n",
    "        dec6 = self.decoder6(dec6)\n",
    "        dec5 = self.upconv5(dec6)\n",
    "        dec5 = torch.cat((dec5, enc4), dim=1)\n",
    "        dec5 = self.decoder5(dec5)\n",
    "        dec4 = self.upconv4(dec5)\n",
    "        dec4 = torch.cat((dec4, enc3), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc2), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc1), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.decoder1(dec2)\n",
    "        return dec1\n",
    "\n",
    "# Crear el dataset y los loaders\n",
    "image_folder = r'C:\\tesis\\Imagenes Kaggle\\all_images\\converted_images_16bits'\n",
    "mask_folder = r'C:\\tesis\\transformadas\\mascaras'\n",
    "\n",
    "# Dataset con transformaciones\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder, augment=False):\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.augment = augment\n",
    "        self.images = os.listdir(image_folder)\n",
    "        self.masks = os.listdir(mask_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.images[idx])\n",
    "        mask_name = os.path.join(self.mask_folder, self.masks[idx])\n",
    "\n",
    "        # Cargar imagen y máscara\n",
    "        image = Image.open(img_name).convert('I;16')\n",
    "        mask = Image.open(mask_name).convert('L')\n",
    "\n",
    "        # Normalizar intensidades\n",
    "        image = np.array(image).astype(np.float32) / 65536.0  \n",
    "        mask = np.array(mask).astype(np.float32) / 255.0\n",
    "\n",
    "        if self.augment:\n",
    "            seed = random.randint(0, 10000)\n",
    "            random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "            # Volteos\n",
    "            if random.random() > 0.5:\n",
    "                image = np.fliplr(image).copy()\n",
    "                mask = np.fliplr(mask).copy()\n",
    "\n",
    "            if random.random() > 0.5:\n",
    "                image = np.flipud(image).copy()\n",
    "                mask = np.flipud(mask).copy()\n",
    "\n",
    "            # Rotación moderada (-10° a 10°)\n",
    "            angle = random.uniform(-10, 10)\n",
    "            image = TF.rotate(Image.fromarray((image * 255).astype(np.uint8)), angle)\n",
    "            mask = TF.rotate(Image.fromarray((mask * 255).astype(np.uint8)), angle)\n",
    "\n",
    "            # Recorte aleatorio con redimensionado\n",
    "            crop_transform = T.RandomResizedCrop(size=(512, 512), scale=(0.8, 1.0))\n",
    "            image = crop_transform(Image.fromarray((image * 255).astype(np.uint8)))\n",
    "            mask = crop_transform(Image.fromarray((mask * 255).astype(np.uint8)))\n",
    "\n",
    "            # Convertir a numpy después de transformaciones\n",
    "            image = np.array(image).astype(np.float32) / 255.0\n",
    "            mask = np.array(mask).astype(np.float32) / 255.0\n",
    "\n",
    "        # Convertir a tensores\n",
    "        image = torch.tensor(image).unsqueeze(0)\n",
    "        mask = torch.tensor(mask).unsqueeze(0)\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "# Función para calcular precisión\n",
    "def calculate_precision(predictions, masks):\n",
    "    binary_predictions = (predictions > 0.5).float()\n",
    "    TP = ((binary_predictions == 1) & (masks == 1)).float().sum()\n",
    "    FP = ((binary_predictions == 1) & (masks == 0)).float().sum()\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    return precision.item()\n",
    "\n",
    "# Función para calcular exactitud (accuracy)\n",
    "def calculate_accuracy(predictions, masks):\n",
    "    binary_predictions = (predictions > 0.5).float()\n",
    "    correct = (binary_predictions == masks).float().sum()\n",
    "    total = masks.numel()\n",
    "    accuracy = correct / total\n",
    "    return accuracy.item()\n",
    "\n",
    "# Crear los datasets\n",
    "train_dataset = CustomDataset(\n",
    "    image_folder=image_folder,\n",
    "    mask_folder=mask_folder,\n",
    "    augment=True  \n",
    ")\n",
    "\n",
    "val_dataset = CustomDataset(\n",
    "    image_folder=image_folder,\n",
    "    mask_folder=mask_folder,\n",
    "    augment=False \n",
    ")\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    image_folder=image_folder,\n",
    "    mask_folder=mask_folder,\n",
    "    augment=False \n",
    ")\n",
    "\n",
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=15, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'Counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Val_dec ({self.val_loss_min:.3f} --> {val_loss:.3f}). Guardando...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "\n",
    "# Función de pérdida ponderada\n",
    "pos_weight=5\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight=pos_weight):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        weights = targets * self.pos_weight + (1 - targets) * 1\n",
    "        bce = F.binary_cross_entropy_with_logits(outputs, targets, reduction='none')\n",
    "        weighted_bce = weights * bce\n",
    "        return weighted_bce.mean()\n",
    "\n",
    "\n",
    "# Inicializar el modelo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "criterion = WeightedBCELoss(pos_weight=pos_weight)  # Ajusta este valor como sea necesario\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Crear el dataset\n",
    "custom_dataset = CustomDataset(image_folder=image_folder, mask_folder=mask_folder)\n",
    "\n",
    "# Calcular tamaños\n",
    "dataset_size = len(custom_dataset)\n",
    "train_size = int(0.75 * dataset_size)\n",
    "test_size = int(0.15 * dataset_size)\n",
    "val_size = dataset_size - train_size - test_size  \n",
    "\n",
    "# Dividir los datasets\n",
    "train_dataset, test_dataset, val_dataset = random_split(custom_dataset, [train_size, test_size, val_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(patience=15, verbose=True)\n",
    "\n",
    "# Entrenamiento\n",
    "num_epochs = 600\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    total_train_accuracy = 0.0\n",
    "    total_train_precision = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = calculate_accuracy(outputs, masks)\n",
    "        precision = calculate_precision(outputs, masks)\n",
    "        total_train_loss += loss.item()\n",
    "        total_train_accuracy += accuracy\n",
    "        total_train_precision += precision\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_train_accuracy = total_train_accuracy / len(train_loader)\n",
    "    avg_train_precision = total_train_precision / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    total_val_accuracy = 0.0\n",
    "    total_val_precision = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in val_loader:\n",
    "            val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            val_loss = criterion(val_outputs, val_masks)\n",
    "\n",
    "            val_accuracy = calculate_accuracy(val_outputs, val_masks)\n",
    "            val_precision = calculate_precision(val_outputs, val_masks)\n",
    "            total_val_loss += val_loss.item()\n",
    "            total_val_accuracy += val_accuracy\n",
    "            total_val_precision += val_precision\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_val_accuracy = total_val_accuracy / len(val_loader)\n",
    "    avg_val_precision = total_val_precision / len(val_loader)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Loss: {avg_train_loss:.4f}, Prec: {avg_train_precision:.4f}, Acc: {avg_train_accuracy:.4f}, '\n",
    "          f'Val_Loss: {avg_val_loss:.4f}, Val_Prec: {avg_val_precision:.4f}, Val_Acc: {avg_val_accuracy:.4f}, '\n",
    "          f'Time: {epoch_time:.2f} sec')\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(avg_val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Cargar el mejor modelo\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
